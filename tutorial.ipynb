{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### In this notebook, we will give a tutorial on how to use `exp_loop` for  running experiments in `BoRisk`.\n",
    "\n",
    "For this tutorial, we will be using the 2D `Branin` function, which is available at\n",
    "`BoRisk/test_functions/function_picker.py`. `Branin` function will stand in for ",
    "`F(x, w)` with first dimension of the input being `x` and the second dimension being `w`.\n",
    "\n",
    "To use custom functions, implement your function as a subclass of\n",
    "`SyntheticTestFunction`, and import it into `function_picker.py`. See\n",
    "`BoRisk/test_functions/` for examples.\n",
    "\n",
    "The `exp_loop` takes in a number of keyword arguments as input, which specify the\n",
    "function as well as the experiment settings. The full list of arguments can be found in\n",
    " the docstrings of `exp_loop` and `Experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from BoRisk import exp_loop\n",
    "\n",
    "args_dict = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will specify the details of our experiment by filling in `args_dict`.\n",
    "\n",
    "For `function_name` we will use `branin` which maps to the `Branin` function in\n",
    "`function_picker.py`. The seed is useful for synchronizing the initial samples when\n",
    "benchmarking different algorithms, and can be specified as any dummy value here.\n",
    "\n",
    "The `filename` is the name of the file in which to save the experiment output. It will\n",
    "typically be appended depending on the values of some of the other arguments. This\n",
    "helps avoid user error when the same `filename` is passed for two different experiments.\n",
    "If the output file with the same name exists, `exp_loop` will read the existing output,\n",
    " reconstruct the experiment state and continue the experiment for the remaining\n",
    " iterations. This is helpful when an experiment gets killed due to a numerical or a\n",
    " memory error, or when we want to add additional iterations. The output files are\n",
    " placed in `exp_output/` by default.\n",
    "\n",
    "For starters, we will set `iterations=5`, i.e., run only 5 BO iterations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "args_dict[\"function_name\"] = \"branin\"\n",
    "args_dict[\"seed\"] = 0  # dummy\n",
    "args_dict[\"filename\"] = \"tutorial_branin\"\n",
    "args_dict[\"iterations\"] = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `Experiment` class accepts many arguments which specify many of the details. We\n",
    "will specify some of these to customize our experiment. The defaults can be found in\n",
    "the docstring.\n",
    "\n",
    "We will leave `dim_w = 1` as the default since we are using a 1D `W`. Note that `w` is\n",
    "always assumed to be the last `dim_w` dimension of the function input, i.e., `F(X) = F\n",
    "(x, w)` where `w = X[..., -dim_w:]`.\n",
    "\n",
    "We can specify the observation noise level by setting `noise_std`.\n",
    "\n",
    "We will reduce `num_fantasies` to `4` to speed up the tutorial. Similarly, we\n",
    "will specify small values for the optimization options, including `num_restarts` and\n",
    "`raw_multiplier`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "args_dict[\"dim_w\"] = 1\n",
    "args_dict[\"noise_std\"] = 1.0\n",
    "args_dict[\"num_fantasies\"] = 4\n",
    "args_dict[\"num_restarts\"] = 10\n",
    "args_dict[\"raw_multiplier\"] = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can specify the risk level `alpha`, which is set to `0.7` by default. Let's use\n",
    "`0.5` for this example. To completely specify the risk measure, we can set the `CVaR`\n",
    "argument, which is `False` by default. Let's set this to `True` so that our risk\n",
    "measure is CVaR at risk level `alpha=0.5`.\n",
    "\n",
    "The random sampling method `rho-random` presented in the paper can be used by\n",
    "specifying `random_sampling=True` here, which we will not be using.\n",
    "\n",
    "The `Experiment` class supports `dtype` and `device` arguments, which correspond to their\n",
    " definitions in `PyTorch`. For this experiment, we will use `cuda` if it is available."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "args_dict[\"alpha\"] = 0.5\n",
    "args_dict[\"device\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have several arguments which specify which BoRisk acquisition function to use. The\n",
    "`apx`, which is `True` by default, corresponds to `rhoKGapx` acquisition function,\n",
    "which is the\n",
    "recommended first choice, and will be used here. Setting `apx=False` would instead use\n",
    "the `rhoKG` acquisition function, which is significantly more expensive to optimize.\n",
    "\n",
    "Other alternatives include `apx_cvar` and `tts_apx_cvar`, which are two versions of a\n",
    "`CVaR` specific approximation that is not presented in the paper. Additionally, we also\n",
    " have `one_shot`, which, paired with `apx=False`, uses the one-shot optimization\n",
    " approach to optimize `rhoKG`. This speeds up the optimization, but reduces the\n",
    " algorithm performance. One last argument is the `tts_frequency`, which specifies the\n",
    " frequency of two time scale optimization as explained in the paper.\n",
    "\n",
    "The remaining arguments we will specify relate to the distribution of the random\n",
    "variable `W`. By default, `W` is assumed to be continuous uniform in `[0, 1]^dim_w`. If\n",
    " using other continuous distributions, we recommend performing the inverse CDF\n",
    " transformation within the test function itself. The `Experiment` class does not have\n",
    " built-in support for non-uniform continuous distributions. When `W` is continuous,\n",
    "  `fix_samples=True` is used to fix the samples `w_{1:L}` (see Section 4 of the paper)\n",
    "  for the SAA approach. The `num_samples` argument is used to specify the number of\n",
    "  samples `L` here.\n",
    "\n",
    "If using a discrete distribution, the domain of `W`, scaled down to `[0, 1]^dim_w` can\n",
    "be specified using the `w_samples` argument. If the distribution is non-uniform, the\n",
    "probability mass of each sample of `W` can be specified using the `weights` argument.\n",
    "\n",
    "For this example, let's use `w_samples = [0.0, 0.2, 0.5, 0.8, 1.0]` with\n",
    "`weights = [0.1, 0.1, 0.3, 0.3, 0.2]`.\n",
    "\n",
    "With `w_samples` specified, we can also specify the samples to use for initializing the\n",
    " GP model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "args_dict[\"w_samples\"] = torch.tensor([0.0, 0.2, 0.5, 0.8, 1.0]).reshape(-1, 1)\n",
    "args_dict[\"weights\"] = torch.tensor([0.1, 0.1, 0.3, 0.3, 0.2])\n",
    "args_dict[\"init_samples\"] = torch.tensor(\n",
    "    [\n",
    "        [0.3, 0.0],\n",
    "        [0.5, 0.5],\n",
    "        [0.75, 1.0],\n",
    "        [0.15, 0.8],\n",
    "        [0.5, 0.8],\n",
    "        [0.4, 0.2],\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are now ready to run the experiment. The next cell will initialize the experiment\n",
    "and perform 5 iterations of BO."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "Current best solution, value:  tensor([0.1500]) tensor(3.4822)\n",
      "Candidate:  tensor([[0., 0.]])  KG value:  tensor(-23.4025)\n",
      "Iteration completed in 0.4641389846801758\n",
      "iter time: 0.619044303894043 \n",
      "Starting iteration 1\n",
      "Current best solution, value:  tensor([0.3000]) tensor(20.5553)\n",
      "Candidate:  tensor([[0.5865, 0.5000]])  KG value:  tensor(-7.7518)\n",
      "Iteration completed in 0.7036099433898926\n",
      "iter time: 0.8880550861358643 \n",
      "Starting iteration 2\n",
      "Current best solution, value:  tensor([0.3000]) tensor(15.2603)\n",
      "Candidate:  tensor([[0.5605, 0.2000]])  KG value:  tensor(-14.4466)\n",
      "Iteration completed in 1.3589019775390625\n",
      "iter time: 1.4711759090423584 \n",
      "Starting iteration 3\n",
      "Current best solution, value:  tensor([0.1500]) tensor(10.7187)\n",
      "Candidate:  tensor([[0.9169, 0.5000]])  KG value:  tensor(0.4796)\n",
      "Iteration completed in 1.485734224319458\n",
      "iter time: 1.6614959239959717 \n",
      "Starting iteration 4\n",
      "Current best solution, value:  tensor([0.1500]) tensor(14.0855)\n",
      "Candidate:  tensor([[1.0000, 0.8000]])  KG value:  tensor(-16.1363)\n",
      "Iteration completed in 1.9345488548278809\n",
      "iter time: 2.2424252033233643 \n",
      "Current best solution, value:  tensor([[0.2396]]) tensor(4.4957)\n",
      "total time:  7.301656246185303\n",
      "CPU times: user 7.1 s, sys: 358 ms, total: 7.46 s\n",
      "Wall time: 7.3 s\n"
     ]
    }
   ],
   "source": [
    "args_dict[\"verbose\"] = True\n",
    "\n",
    "%time exp = exp_loop(**args_dict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output file for this experiment can be found at\n",
    "`exp_output/tutorial_branin_a=0.5_cont_weights.pt`. It contains more information than\n",
    "we should ever need. Let's load it and verify that we indeed have the output for each\n",
    "of 5 iterations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 'final_solution', 'final_value'])\n",
      "dict_keys(['state_dict', 'train_Y', 'train_X', 'current_best_sol', 'current_best_value', 'acqf_value', 'candidate', 'function', 'dim', 'dim_w', 'num_fantasies', 'num_restarts', 'raw_multiplier', 'alpha', 'q', 'num_repetitions', 'verbose', 'maxiter', 'CVaR', 'random_sampling', 'expectation', 'dtype', 'device', 'apx', 'apx_cvar', 'tts_apx_cvar', 'disc', 'tts_frequency', 'num_inner_restarts', 'inner_raw_multiplier', 'weights', 'fix_samples', 'one_shot', 'low_fantasies', 'random_w', 'noise_std', 'w_samples', 'init_samples', 'dim_x', 'num_samples', 'fixed_samples', 'passed', 'fit_count'])\n"
     ]
    }
   ],
   "source": [
    "output_file = \"exp_output/tutorial_branin_a=0.5_cont_weights.pt\"\n",
    "output = torch.load(output_file)\n",
    "print(output.keys())\n",
    "print(output[0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now run the experiment for 15 more iterations. This is purely for demonstrating\n",
    " the warm-start / continue functionality built into `exp_loop`. This proved very useful\n",
    "  when we were running rather expensive experiments on the cluster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 5\n",
      "Current best solution, value:  tensor([0.1500]) tensor(14.8123)\n",
      "Candidate:  tensor([[0.2944, 0.5000]])  KG value:  tensor(-11.0697)\n",
      "Iteration completed in 1.0468389987945557\n",
      "iter time: 1.151777982711792 \n",
      "Starting iteration 6\n",
      "Current best solution, value:  tensor([0.1500]) tensor(12.3591)\n",
      "Candidate:  tensor([[0.9743, 0.0000]])  KG value:  tensor(-11.3711)\n",
      "Iteration completed in 1.722545862197876\n",
      "iter time: 1.8498108386993408 \n",
      "Starting iteration 7\n",
      "Current best solution, value:  tensor([0.2944]) tensor(10.6478)\n",
      "Candidate:  tensor([[0.8973, 1.0000]])  KG value:  tensor(-12.3192)\n",
      "Iteration completed in 1.6161069869995117\n",
      "iter time: 1.817112922668457 \n",
      "Starting iteration 8\n",
      "Current best solution, value:  tensor([0.1500]) tensor(7.6724)\n",
      "Candidate:  tensor([[0.2543, 0.2000]])  KG value:  tensor(-16.1955)\n",
      "Iteration completed in 2.8807051181793213\n",
      "iter time: 3.071120023727417 \n",
      "Starting iteration 9\n",
      "Current best solution, value:  tensor([0.1500]) tensor(10.8443)\n",
      "Candidate:  tensor([[0.4373, 0.0000]])  KG value:  tensor(-10.4250)\n",
      "Iteration completed in 1.8344190120697021\n",
      "iter time: 1.947972059249878 \n",
      "Starting iteration 10\n",
      "Current best solution, value:  tensor([0.1500]) tensor(11.4545)\n",
      "Candidate:  tensor([[1.0000, 0.8000]])  KG value:  tensor(-11.6597)\n",
      "Iteration completed in 1.07830810546875\n",
      "iter time: 1.3195829391479492 \n",
      "Starting iteration 11\n",
      "Current best solution, value:  tensor([0.1500]) tensor(7.8383)\n",
      "Candidate:  tensor([[0.9255, 0.8000]])  KG value:  tensor(-12.8384)\n",
      "Iteration completed in 1.696080207824707\n",
      "iter time: 1.870452880859375 \n",
      "Starting iteration 12\n",
      "Current best solution, value:  tensor([0.1500]) tensor(4.7867)\n",
      "Candidate:  tensor([[0.1154, 0.0000]])  KG value:  tensor(-19.2421)\n",
      "Iteration completed in 2.3148579597473145\n",
      "iter time: 2.6973989009857178 \n",
      "Starting iteration 13\n",
      "Current best solution, value:  tensor([0.1500]) tensor(6.8327)\n",
      "Candidate:  tensor([[0.6242, 0.8000]])  KG value:  tensor(-17.3255)\n",
      "Iteration completed in 1.9737768173217773\n",
      "iter time: 2.15407395362854 \n",
      "Starting iteration 14\n",
      "Current best solution, value:  tensor([0.1500]) tensor(7.9169)\n",
      "Candidate:  tensor([[0.0141, 0.5000]])  KG value:  tensor(-14.8185)\n",
      "Iteration completed in 2.52842116355896\n",
      "iter time: 2.7191240787506104 \n",
      "Starting iteration 15\n",
      "Current best solution, value:  tensor([0.1154]) tensor(7.9373)\n",
      "Candidate:  tensor([[0.8899, 0.5000]])  KG value:  tensor(-11.4787)\n",
      "Iteration completed in 1.4219880104064941\n",
      "iter time: 1.4740359783172607 \n",
      "Starting iteration 16\n",
      "Current best solution, value:  tensor([0.1500]) tensor(20.0390)\n",
      "Candidate:  tensor([[0.5231, 0.5000]])  KG value:  tensor(-4.7946)\n",
      "Iteration completed in 2.169076919555664\n",
      "iter time: 2.367372989654541 \n",
      "Starting iteration 17\n",
      "Current best solution, value:  tensor([0.1500]) tensor(6.4783)\n",
      "Candidate:  tensor([[0.0000, 0.5000]])  KG value:  tensor(-16.4389)\n",
      "Iteration completed in 1.020280122756958\n",
      "iter time: 1.2146039009094238 \n",
      "Starting iteration 18\n",
      "Current best solution, value:  tensor([0.1500]) tensor(12.9691)\n",
      "Candidate:  tensor([[0.9966, 0.0000]])  KG value:  tensor(-10.8149)\n",
      "Iteration completed in 1.948547124862671\n",
      "iter time: 2.1190450191497803 \n",
      "Starting iteration 19\n",
      "Current best solution, value:  tensor([0.1154]) tensor(9.2328)\n",
      "Candidate:  tensor([[1.0000, 0.5000]])  KG value:  tensor(-10.6244)\n",
      "Iteration completed in 2.4751617908477783\n",
      "iter time: 2.5580978393554688 \n",
      "Current best solution, value:  tensor([[0.1483]]) tensor(5.8088)\n",
      "total time:  31.18269181251526\n",
      "CPU times: user 30.4 s, sys: 1.19 s, total: 31.6 s\n",
      "Wall time: 31.2 s\n",
      "dict_keys([0, 1, 2, 3, 4, 'final_solution', 'final_value', 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "args_dict[\"iterations\"] = 20\n",
    "%time exp = exp_loop(**args_dict)\n",
    "\n",
    "output_file = \"exp_output/tutorial_branin_a=0.5_cont_weights.pt\"\n",
    "output = torch.load(output_file)\n",
    "print(output.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we chose to use the `verbose` argument to print out the best values found so far.\n",
    " The output contains the best solution the algorithm found at the beginning of each\n",
    " iteration, as well as at the end of the experiment. These values can easily be\n",
    " extracted using a for loop, and the solution can be evaluated with a chosen objective.\n",
    "  A not-so-friendly example of how we did this for reading batches of experiment\n",
    "  outputs can be found in `helper_fns/ex_output_read.py`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
